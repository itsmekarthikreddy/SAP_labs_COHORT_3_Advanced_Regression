{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# House Price Prediction â€” Regularised Regression\n",
    "\n",
    "This notebook implements the full analysis required by the assignment. It is organized into sections: imports, data loading, preprocessing, hyperparameter selection (Ridge & Lasso), feature importance, `alpha` doubling experiment, and retraining when top features are unavailable.\n",
    "\n",
    "Kernel:  Python 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Imports and configuration\n",
    "\n",
    "Standard imports and plotting configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell: imports\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "sns.set(style='whitegrid')\n",
    "print('Imports OK')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility imports used later in the notebook\n",
    "import json\n",
    "from pprint import pprint\n",
    "print('json and pprint imported')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Load data and quick checks\n",
    "\n",
    "Load `train.csv` (must be in the workspace root) and show basic diagnostics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = Path('train.csv')\n",
    "assert p.exists(), 'train.csv not found in workspace root'\n",
    "df = pd.read_csv(p)\n",
    "print('Shape:', df.shape)\n",
    "df.head(3)\n",
    "\n",
    "# Basic missingness\n",
    "miss = df.isnull().mean().sort_values(ascending=False)\n",
    "miss[miss>0].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1) Exploratory Data Analysis (EDA)\n",
    "\n",
    "Quick EDA: target distribution, missingness, duplicates, top numeric correlations, and a simple derived feature (`TotalSF`) if available. Figures are saved to disk for the report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EDA: target distribution, missingness, correlations, duplicates, derived feature\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "plt.rcParams.update({'figure.max_open_warning': 0})\n",
    "\n",
    "# Target distribution\n",
    "plt.figure(figsize=(8,4))\n",
    "sns.histplot(df['SalePrice'], kde=True, color='C0')\n",
    "plt.title('SalePrice distribution')\n",
    "plt.tight_layout()\n",
    "plt.savefig('fig_target_hist.png', bbox_inches='tight')\n",
    "plt.close()\n",
    "\n",
    "plt.figure(figsize=(8,4))\n",
    "sns.histplot(np.log1p(df['SalePrice']), kde=True, color='C1')\n",
    "plt.title('log1p(SalePrice) distribution')\n",
    "plt.tight_layout()\n",
    "plt.savefig('fig_target_log_hist.png', bbox_inches='tight')\n",
    "plt.close()\n",
    "\n",
    "# Missingness summary and small heatmap (top missing columns)\n",
    "miss = df.isnull().mean().sort_values(ascending=False)\n",
    "top_miss = miss[miss>0].head(20)\n",
    "print('Top missing columns (fraction missing):')\n",
    "print(top_miss)\n",
    "\n",
    "if len(top_miss):\n",
    "    plt.figure(figsize=(10,6))\n",
    "    sns.heatmap(df[top_miss.index].isnull(), cbar=False)\n",
    "    plt.title('Missingness heatmap (top columns)')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('fig_missing_heatmap.png', bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "# Duplicates check\n",
    "dups = df.duplicated().sum()\n",
    "print('Duplicate rows:', dups)\n",
    "\n",
    "# Numeric correlations with target\n",
    "num = df.select_dtypes(include=['int64','float64']).drop(columns=['SalePrice'])\n",
    "corrs = num.corrwith(df['SalePrice']).abs().sort_values(ascending=False)\n",
    "print('Top numeric correlations with SalePrice:')\n",
    "print(corrs.head(10))\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "sns.barplot(x=corrs.head(10).values, y=corrs.head(10).index, palette='viridis')\n",
    "plt.title('Top numeric features correlated with SalePrice')\n",
    "plt.tight_layout()\n",
    "plt.savefig('fig_top_corrs.png', bbox_inches='tight')\n",
    "plt.close()\n",
    "\n",
    "# Correlation heatmap for top numeric features (if enough exist)\n",
    "top_nums = corrs.head(15).index.tolist()\n",
    "if len(top_nums) > 1:\n",
    "    plt.figure(figsize=(10,8))\n",
    "    sns.heatmap(df[top_nums + ['SalePrice']].corr(), annot=False, cmap='coolwarm')\n",
    "    plt.title('Correlation matrix (top numeric features)')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('fig_corr_matrix.png', bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "# Simple derived feature: TotalSF if 1st/2nd/TotalBsmt present\n",
    "derived_cols = ['1stFlrSF','2ndFlrSF','TotalBsmtSF']\n",
    "if all(c in df.columns for c in derived_cols):\n",
    "    df['TotalSF'] = df['1stFlrSF'].fillna(0) + df['2ndFlrSF'].fillna(0) + df['TotalBsmtSF'].fillna(0)\n",
    "    print('Derived feature `TotalSF` created (sum of 1stFlrSF, 2ndFlrSF, TotalBsmtSF)')\n",
    "    plt.figure(figsize=(8,4))\n",
    "    sns.histplot(df['TotalSF'], kde=True, color='C2')\n",
    "    plt.title('TotalSF distribution')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('fig_totalSF.png', bbox_inches='tight')\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) Preprocessing pipeline\n",
    "\n",
    "Median imputation for numerics, most-frequent for categoricals, StandardScaler for numerics, OneHotEncoder for categoricals."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1) Train/Test Split and Hold-out Evaluation\n",
    "\n",
    "We split the data into train and test sets (80/20). All model selection and CV are performed on the train set. Final RMSE is reported on the hold-out test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "\n",
    "# Separate target\n",
    "y = df['SalePrice']\n",
    "X = df.drop(columns=['SalePrice'])\n",
    "numeric_cols = X.select_dtypes(include=['int64','float64']).columns.tolist()\n",
    "cat_cols = X.select_dtypes(include=['object']).columns.tolist()\n",
    "print('Numeric cols:', len(numeric_cols), 'Categorical cols:', len(cat_cols))\n",
    "\n",
    "numeric_transformer = Pipeline([('imputer', SimpleImputer(strategy='median')),('scaler', StandardScaler())])\n",
    "categorical_transformer = Pipeline([('imputer', SimpleImputer(strategy='most_frequent')),('onehot', OneHotEncoder(handle_unknown='ignore', sparse_output=False))])\n",
    "preprocessor = ColumnTransformer([('num', numeric_transformer, numeric_cols),('cat', categorical_transformer, cat_cols)])\n",
    "print('Preprocessor ready')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4) Hyperparameter selection (alpha grid) and cross-validation\n",
    "\n",
    "We use a log-spaced alpha grid and 5-fold CV. For Lasso we use `LassoCV` to get the full path; for Ridge we compute CV RMSE per alpha and pick the best."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "from sklearn.linear_model import LassoCV, Ridge\n",
    "alphas = np.logspace(-3, 3, 50)\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "# Ridge CV (manual grid)\n",
    "ridge_rmse = []\n",
    "from sklearn.pipeline import make_pipeline\n",
    "for a in alphas:\n",
    "    pipe = make_pipeline(preprocessor, Ridge(alpha=a))\n",
    "    scores = cross_val_score(pipe, X, y, cv=kf, scoring='neg_mean_squared_error')\n",
    "    ridge_rmse.append(np.sqrt(-scores).mean())\n",
    "# LassoCV (uses internal CV)\n",
    "lasso_pipe = make_pipeline(preprocessor, LassoCV(alphas=alphas, cv=kf, random_state=42, max_iter=10000))\n",
    "lasso_pipe.fit(X, y)\n",
    "best_alpha_lasso = lasso_pipe.named_steps['lassocv'].alpha_\n",
    "# Pick best ridge alpha from grid\n",
    "best_idx = int(np.argmin(ridge_rmse))\n",
    "best_alpha_ridge = float(alphas[best_idx])\n",
    "# Compute CV RMSE summary\n",
    "ridge_rmse_cv = float(ridge_rmse[best_idx])\n",
    "# For Lasso, compute CV RMSE from mse_path_ if available\n",
    "lasso_model = lasso_pipe.named_steps['lassocv']\n",
    "mse_path = getattr(lasso_model, 'mse_path_', None)\n",
    "if mse_path is not None:\n",
    "    lasso_rmse_vals = np.sqrt(mse_path).mean(axis=1)\n",
    "    # find index for selected alpha in model.alphas_\n",
    "    if hasattr(lasso_model, 'alphas_'):\n",
    "        idx = int(np.argmin(np.abs(lasso_model.alphas_ - lasso_model.alpha_)))\n",
    "        lasso_rmse_cv = float(lasso_rmse_vals[idx])\n",
    "    else:\n",
    "        lasso_rmse_cv = float(np.sqrt(np.mean((y - lasso_pipe.predict(X))**2)))\n",
    "else:\n",
    "    lasso_rmse_cv = float(np.sqrt(np.mean((y - lasso_pipe.predict(X))**2)))\n",
    "print('Best Ridge alpha:', best_alpha_ridge)\n",
    "print('Best Lasso alpha:', best_alpha_lasso)\n",
    "print('Ridge CV RMSE:', ridge_rmse_cv)\n",
    "print('Lasso CV RMSE:', lasso_rmse_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure a hold-out train/test split exists before training on the train set\n",
    "from sklearn.model_selection import train_test_split\n",
    "if 'X' not in globals() or 'y' not in globals():\n",
    "    y = df['SalePrice']\n",
    "    X = df.drop(columns=['SalePrice'])\n",
    "# create a deterministic 80/20 split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "print('Train / Test shapes:', X_train.shape, X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Repeat model selection on train set only, then evaluate on test set\n",
    "ridge_rmse_tr = []\n",
    "for a in alphas:\n",
    "    pipe = make_pipeline(preprocessor, Ridge(alpha=a))\n",
    "    scores = cross_val_score(pipe, X_train, y_train, cv=kf, scoring='neg_mean_squared_error')\n",
    "    ridge_rmse_tr.append(np.sqrt(-scores).mean())\n",
    "best_idx_tr = int(np.argmin(ridge_rmse_tr))\n",
    "best_alpha_ridge_tr = float(alphas[best_idx_tr])\n",
    "ridge_final_tr = make_pipeline(preprocessor, Ridge(alpha=best_alpha_ridge_tr))\n",
    "ridge_final_tr.fit(X_train, y_train)\n",
    "ridge_test_preds = ridge_final_tr.predict(X_test)\n",
    "ridge_test_rmse = float(np.sqrt(np.mean((y_test - ridge_test_preds)**2)))\n",
    "print('Ridge test RMSE:', ridge_test_rmse)\n",
    "# LassoCV on train set\n",
    "lasso_pipe_tr = make_pipeline(preprocessor, LassoCV(alphas=alphas, cv=kf, random_state=42, max_iter=10000))\n",
    "lasso_pipe_tr.fit(X_train, y_train)\n",
    "best_alpha_lasso_tr = lasso_pipe_tr.named_steps['lassocv'].alpha_\n",
    "lasso_test_preds = lasso_pipe_tr.predict(X_test)\n",
    "lasso_test_rmse = float(np.sqrt(np.mean((y_test - lasso_test_preds)**2)))\n",
    "print('Lasso test RMSE:', lasso_test_rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5) Feature importance\n",
    "\n",
    "Map fitted coefficients back to original feature names and display the top predictors for Ridge and Lasso."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_feature_names_from_preprocessor(pre, numeric_cols, cat_cols):\n",
    "    pre.fit(X)\n",
    "    num_feats = numeric_cols\n",
    "    cat_feats = []\n",
    "    if 'cat' in pre.named_transformers_:\n",
    "        cat_pipe = pre.named_transformers_['cat']\n",
    "        if hasattr(cat_pipe, 'named_steps') and 'onehot' in cat_pipe.named_steps:\n",
    "            ohe = cat_pipe.named_steps['onehot']\n",
    "            cat_in = pre.transformers[1][2]\n",
    "            cat_feats = list(ohe.get_feature_names_out(cat_in))\n",
    "    return num_feats + cat_feats\n",
    "\n",
    "\n",
    "def top_features_for_model(pipe, numeric_cols, cat_cols, top_n=10):\n",
    "    # pipe must be fitted\n",
    "    model = pipe.named_steps[list(pipe.named_steps.keys())[-1]]\n",
    "    feat_names = get_feature_names_from_preprocessor(preprocessor, numeric_cols, cat_cols)\n",
    "    coefs = model.coef_\n",
    "    idx = np.argsort(np.abs(coefs))[::-1][:top_n]\n",
    "    return [(feat_names[i], float(coefs[i])) for i in idx if i < len(feat_names)]\n",
    "\n",
    "from sklearn.linear_model import Ridge\n",
    "ridge_final = make_pipeline(preprocessor, Ridge(alpha=best_alpha_ridge))\n",
    "ridge_final.fit(X, y)\n",
    "lasso_final = lasso_pipe\n",
    "lasso_final.fit(X, y)\n",
    "ridge_top = top_features_for_model(ridge_final, numeric_cols, cat_cols, top_n=10)\n",
    "lasso_top = top_features_for_model(lasso_final, numeric_cols, cat_cols, top_n=10)\n",
    "print('Ridge top features:')\n",
    "for f,v in ridge_top:\n",
    "    print(f, v)\n",
    "print('\\nLasso top features:')\n",
    "for f,v in lasso_top:\n",
    "    print(f, v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6) Doubling alpha experiment\n",
    "\n",
    "Retrain models with doubled alpha and report training RMSE to show regularisation effect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "# Retrain Ridge and Lasso with doubled alpha and compute training RMSE for comparison\n",
    "ridge_double = make_pipeline(preprocessor, Ridge(alpha=best_alpha_ridge*2))\n",
    "ridge_double.fit(X, y)\n",
    "from sklearn.linear_model import Lasso\n",
    "lasso_double = make_pipeline(preprocessor, Lasso(alpha=best_alpha_lasso*2, max_iter=10000))\n",
    "lasso_double.fit(X, y)\n",
    "\n",
    "def rmse_on_train(pipe, X_local=X, y_local=y):\n",
    "    preds = pipe.predict(X_local)\n",
    "    return float(np.sqrt(mean_squared_error(y_local, preds)))\n",
    "\n",
    "print('Ridge doubled alpha RMSE (train):', rmse_on_train(ridge_double))\n",
    "print('Lasso doubled alpha RMSE (train):', rmse_on_train(lasso_double))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7) Retrain without top-5 Lasso predictors\n",
    "\n",
    "Drop the top-5 features identified by Lasso and retrain a fallback Lasso model on the reduced dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top5 = [f for f,_ in lasso_top[:5]]\n",
    "print('Top-5 Lasso features to remove:', top5)\n",
    "X_reduced = X.copy()\n",
    "for feat in top5:\n",
    "    if feat in X_reduced.columns:\n",
    "        X_reduced = X_reduced.drop(columns=[feat])\n",
    "    else:\n",
    "        if '_' in feat:\n",
    "            base = feat.split('_')[0]\n",
    "            if base in X_reduced.columns:\n",
    "                X_reduced = X_reduced.drop(columns=[base])\n",
    "\n",
    "numeric_cols_r = X_reduced.select_dtypes(include=['int64','float64']).columns.tolist()\n",
    "cat_cols_r = X_reduced.select_dtypes(include=['object']).columns.tolist()\n",
    "\n",
    "numeric_transformer_r = Pipeline([('imputer', SimpleImputer(strategy='median')),('scaler', StandardScaler())])\n",
    "categorical_transformer_r = Pipeline([('imputer', SimpleImputer(strategy='most_frequent')),('onehot', OneHotEncoder(handle_unknown='ignore', sparse_output=False))])\n",
    "preprocessor_r = ColumnTransformer([('num', numeric_transformer_r, numeric_cols_r),('cat', categorical_transformer_r, cat_cols_r)])\n",
    "\n",
    "from sklearn.linear_model import LassoCV\n",
    "lasso_r = make_pipeline(preprocessor_r, LassoCV(alphas=alphas, cv=kf, random_state=42, max_iter=10000))\n",
    "lasso_r.fit(X_reduced, y)\n",
    "\n",
    "# extract new top features\n",
    "preprocessor_r.fit(X_reduced)\n",
    "if 'cat' in preprocessor_r.named_transformers_:\n",
    "    cat_pipe = preprocessor_r.named_transformers_['cat']\n",
    "    ohe = cat_pipe.named_steps['onehot']\n",
    "    cat_in = preprocessor_r.transformers[1][2]\n",
    "    cat_feats_r = list(ohe.get_feature_names_out(cat_in))\n",
    "else:\n",
    "    cat_feats_r = []\n",
    "feat_names_r = numeric_cols_r + cat_feats_r\n",
    "coefs_r = lasso_r.named_steps['lassocv'].coef_\n",
    "idx_r = np.argsort(np.abs(coefs_r))[::-1][:10]\n",
    "lasso_r_top = [(feat_names_r[i], float(coefs_r[i])) for i in idx_r if i < len(feat_names_r)]\n",
    "print('Top features after removing top-5 Lasso predictors:')\n",
    "for f,v in lasso_r_top:\n",
    "    print(f,v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save summary\n",
    "summary = {\n",
    "    'best_alpha_ridge': best_alpha_ridge,\n",
    "    'best_alpha_lasso': float(best_alpha_lasso),\n",
    "    'ridge_rmse_cv': ridge_rmse_cv,\n",
    "    'lasso_rmse_cv': lasso_rmse_cv,\n",
    "    'ridge_top': ridge_top,\n",
    "    'lasso_top': lasso_top,\n",
    "    'top5_lasso_removed': top5,\n",
    "    'lasso_retrained_top': lasso_r_top,\n",
    "    'ridge_test_rmse': ridge_test_rmse,\n",
    "    'lasso_test_rmse': lasso_test_rmse,\n",
    "}\n",
    "Path('model_summary.json').write_text(json.dumps(summary, indent=2))\n",
    "print('Saved model_summary.json')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
