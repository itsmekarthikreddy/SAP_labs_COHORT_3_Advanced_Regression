{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "256702e3",
   "metadata": {},
   "source": [
    "# House Price Prediction â€” Regularised Regression\n",
    "\n",
    "This notebook implements the full analysis required. It is organized into sections: imports, data loading, preprocessing, hyperparameter selection (Ridge & Lasso), feature importance, `alpha` doubling experiment, and retraining when top features are unavailable.\n",
    "\n",
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dc8c2c1",
   "metadata": {},
   "source": [
    "## 1) Imports and configuration\n",
    "\n",
    "Standard imports and plotting configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6019e699",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imports OK\n"
     ]
    }
   ],
   "source": [
    "# Cell: imports\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "sns.set(style='whitegrid')\n",
    "print('Imports OK')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2add8fb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "json and pprint imported\n"
     ]
    }
   ],
   "source": [
    "# Utility imports used later in the notebook\n",
    "import json\n",
    "from pprint import pprint\n",
    "print('json and pprint imported')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d40562d8",
   "metadata": {},
   "source": [
    "## 2) Load data and quick checks\n",
    "\n",
    "Load `train.csv` (must be in the workspace root) and show basic diagnostics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "70356bee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (1460, 81)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "PoolQC         0.995205\n",
       "MiscFeature    0.963014\n",
       "Alley          0.937671\n",
       "Fence          0.807534\n",
       "MasVnrType     0.597260\n",
       "FireplaceQu    0.472603\n",
       "LotFrontage    0.177397\n",
       "GarageYrBlt    0.055479\n",
       "GarageCond     0.055479\n",
       "GarageType     0.055479\n",
       "dtype: float64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = Path('train.csv')\n",
    "assert p.exists(), 'train.csv not found in workspace root'\n",
    "df = pd.read_csv(p)\n",
    "print('Shape:', df.shape)\n",
    "df.head(3)\n",
    "\n",
    "# Basic missingness\n",
    "miss = df.isnull().mean().sort_values(ascending=False)\n",
    "miss[miss>0].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1edaba7e",
   "metadata": {},
   "source": [
    "## 2.1) Exploratory Data Analysis (EDA)\n",
    "\n",
    "Quick EDA: target distribution, missingness, duplicates, top numeric correlations, and a simple derived feature (`TotalSF`) if available. Figures are saved to disk for the report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "32380451",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top missing columns (fraction missing):\n",
      "PoolQC          0.995205\n",
      "MiscFeature     0.963014\n",
      "Alley           0.937671\n",
      "Fence           0.807534\n",
      "MasVnrType      0.597260\n",
      "FireplaceQu     0.472603\n",
      "LotFrontage     0.177397\n",
      "GarageYrBlt     0.055479\n",
      "GarageCond      0.055479\n",
      "GarageType      0.055479\n",
      "GarageFinish    0.055479\n",
      "GarageQual      0.055479\n",
      "BsmtFinType2    0.026027\n",
      "BsmtExposure    0.026027\n",
      "BsmtQual        0.025342\n",
      "BsmtCond        0.025342\n",
      "BsmtFinType1    0.025342\n",
      "MasVnrArea      0.005479\n",
      "Electrical      0.000685\n",
      "dtype: float64\n",
      "Duplicate rows: 0\n",
      "Top numeric correlations with SalePrice:\n",
      "OverallQual     0.790982\n",
      "GrLivArea       0.708624\n",
      "GarageCars      0.640409\n",
      "GarageArea      0.623431\n",
      "TotalBsmtSF     0.613581\n",
      "1stFlrSF        0.605852\n",
      "FullBath        0.560664\n",
      "TotRmsAbvGrd    0.533723\n",
      "YearBuilt       0.522897\n",
      "YearRemodAdd    0.507101\n",
      "dtype: float64\n",
      "Derived feature `TotalSF` created (sum of 1stFlrSF, 2ndFlrSF, TotalBsmtSF)\n"
     ]
    }
   ],
   "source": [
    "# EDA: target distribution, missingness, correlations, duplicates, derived feature\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "plt.rcParams.update({'figure.max_open_warning': 0})\n",
    "# Target distribution\n",
    "plt.figure(figsize=(8,4))\n",
    "sns.histplot(df['SalePrice'], kde=True, color='C0')\n",
    "plt.title('SalePrice distribution')\n",
    "plt.tight_layout()\n",
    "plt.savefig('fig_target_hist.png', bbox_inches='tight')\n",
    "plt.close()\n",
    "plt.figure(figsize=(8,4))\n",
    "sns.histplot(np.log1p(df['SalePrice']), kde=True, color='C1')\n",
    "plt.title('log1p(SalePrice) distribution')\n",
    "plt.tight_layout()\n",
    "plt.savefig('fig_target_log_hist.png', bbox_inches='tight')\n",
    "plt.close()\n",
    "# Missingness summary and small heatmap (top missing columns)\n",
    "miss = df.isnull().mean().sort_values(ascending=False)\n",
    "top_miss = miss[miss>0].head(20)\n",
    "print('Top missing columns (fraction missing):')\n",
    "print(top_miss)\n",
    "if len(top_miss):\n",
    "    plt.figure(figsize=(10,6))\n",
    "    sns.heatmap(df[top_miss.index].isnull(), cbar=False)\n",
    "    plt.title('Missingness heatmap (top columns)')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('fig_missing_heatmap.png', bbox_inches='tight')\n",
    "    plt.close()\n",
    "# Duplicates check\n",
    "dups = df.duplicated().sum()\n",
    "print('Duplicate rows:', dups)\n",
    "# Numeric correlations with target\n",
    "num = df.select_dtypes(include=['int64','float64']).drop(columns=['SalePrice'])\n",
    "corrs = num.corrwith(df['SalePrice']).abs().sort_values(ascending=False)\n",
    "print('Top numeric correlations with SalePrice:')\n",
    "print(corrs.head(10))\n",
    "plt.figure(figsize=(8,6))\n",
    "sns.barplot(x=corrs.head(10).values, y=corrs.head(10).index, palette='viridis')\n",
    "plt.title('Top numeric features correlated with SalePrice')\n",
    "plt.tight_layout()\n",
    "plt.savefig('fig_top_corrs.png', bbox_inches='tight')\n",
    "plt.close()\n",
    "# Correlation heatmap for top numeric features (if enough exist)\n",
    "top_nums = corrs.head(15).index.tolist()\n",
    "if len(top_nums) > 1:\n",
    "    plt.figure(figsize=(10,8))\n",
    "    sns.heatmap(df[top_nums + ['SalePrice']].corr(), annot=False, cmap='coolwarm')\n",
    "    plt.title('Correlation matrix (top numeric features)')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('fig_corr_matrix.png', bbox_inches='tight')\n",
    "    plt.close()\n",
    "# Simple derived feature: TotalSF if 1st/2nd/TotalBsmt present\n",
    "derived_cols = ['1stFlrSF','2ndFlrSF','TotalBsmtSF']\n",
    "if all(c in df.columns for c in derived_cols):\n",
    "    df['TotalSF'] = df['1stFlrSF'].fillna(0) + df['2ndFlrSF'].fillna(0) + df['TotalBsmtSF'].fillna(0)\n",
    "    print('Derived feature `TotalSF` created (sum of 1stFlrSF, 2ndFlrSF, TotalBsmtSF)')\n",
    "    plt.figure(figsize=(8,4))\n",
    "    sns.histplot(df['TotalSF'], kde=True, color='C2')\n",
    "    plt.title('TotalSF distribution')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('fig_totalSF.png', bbox_inches='tight')\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "404198a8",
   "metadata": {},
   "source": [
    "## 3) Preprocessing pipeline\n",
    "\n",
    "Median imputation for numerics, most-frequent for categoricals, StandardScaler for numerics, OneHotEncoder for categoricals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8f5c3998",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numeric cols: 38 Categorical cols: 43\n",
      "Preprocessor ready\n"
     ]
    }
   ],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "\n",
    "# Separate target\n",
    "y = df['SalePrice']\n",
    "X = df.drop(columns=['SalePrice'])\n",
    "numeric_cols = X.select_dtypes(include=['int64','float64']).columns.tolist()\n",
    "cat_cols = X.select_dtypes(include=['object']).columns.tolist()\n",
    "print('Numeric cols:', len(numeric_cols), 'Categorical cols:', len(cat_cols))\n",
    "\n",
    "numeric_transformer = Pipeline([('imputer', SimpleImputer(strategy='median')),('scaler', StandardScaler())])\n",
    "categorical_transformer = Pipeline([('imputer', SimpleImputer(strategy='most_frequent')),('onehot', OneHotEncoder(handle_unknown='ignore', sparse_output=False))])\n",
    "preprocessor = ColumnTransformer([('num', numeric_transformer, numeric_cols),('cat', categorical_transformer, cat_cols)])\n",
    "print('Preprocessor ready')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef394289",
   "metadata": {},
   "source": [
    "## 4) Hyperparameter selection (alpha grid) and cross-validation\n",
    "\n",
    "We use a log-spaced alpha grid and 5-fold CV. For Lasso we use `LassoCV` to get the full path; for Ridge we compute CV RMSE per alpha and pick the best."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6af1e690",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Ridge alpha: 14.563484775012444\n",
      "Best Lasso alpha: 138.9495494373136\n",
      "Ridge CV RMSE: 33042.22437265117\n",
      "Lasso CV RMSE: 31567.206937142975\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "from sklearn.linear_model import LassoCV, Ridge\n",
    "alphas = np.logspace(-3, 3, 50)\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "# Ridge CV (manual grid)\n",
    "ridge_rmse = []\n",
    "from sklearn.pipeline import make_pipeline\n",
    "for a in alphas:\n",
    "    pipe = make_pipeline(preprocessor, Ridge(alpha=a))\n",
    "    scores = cross_val_score(pipe, X, y, cv=kf, scoring='neg_mean_squared_error')\n",
    "    ridge_rmse.append(np.sqrt(-scores).mean())\n",
    "# LassoCV (uses internal CV)\n",
    "lasso_pipe = make_pipeline(preprocessor, LassoCV(alphas=alphas, cv=kf, random_state=42, max_iter=10000))\n",
    "lasso_pipe.fit(X, y)\n",
    "best_alpha_lasso = lasso_pipe.named_steps['lassocv'].alpha_\n",
    "# Pick best ridge alpha from grid\n",
    "best_idx = int(np.argmin(ridge_rmse))\n",
    "best_alpha_ridge = float(alphas[best_idx])\n",
    "# Compute CV RMSE summary\n",
    "ridge_rmse_cv = float(ridge_rmse[best_idx])\n",
    "# For Lasso, compute CV RMSE from mse_path_ if available\n",
    "lasso_model = lasso_pipe.named_steps['lassocv']\n",
    "mse_path = getattr(lasso_model, 'mse_path_', None)\n",
    "if mse_path is not None:\n",
    "    lasso_rmse_vals = np.sqrt(mse_path).mean(axis=1)\n",
    "    # find index for selected alpha in model.alphas_\n",
    "    if hasattr(lasso_model, 'alphas_'):\n",
    "        idx = int(np.argmin(np.abs(lasso_model.alphas_ - lasso_model.alpha_)))\n",
    "        lasso_rmse_cv = float(lasso_rmse_vals[idx])\n",
    "    else:\n",
    "        lasso_rmse_cv = float(np.sqrt(np.mean((y - lasso_pipe.predict(X))**2)))\n",
    "else:\n",
    "    lasso_rmse_cv = float(np.sqrt(np.mean((y - lasso_pipe.predict(X))**2)))\n",
    "print('Best Ridge alpha:', best_alpha_ridge)\n",
    "print('Best Lasso alpha:', best_alpha_lasso)\n",
    "print('Ridge CV RMSE:', ridge_rmse_cv)\n",
    "print('Lasso CV RMSE:', lasso_rmse_cv)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db63645e",
   "metadata": {},
   "source": [
    "## 5) Feature importance\n",
    "\n",
    "Map fitted coefficients back to original feature names and display the top predictors for Ridge and Lasso."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "18bec683",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ridge top features:\n",
      "Neighborhood_NoRidge 28331.71163269879\n",
      "Neighborhood_StoneBr 23872.972516974092\n",
      "RoofMatl_ClyTile -22602.71207988804\n",
      "RoofMatl_WdShngl 21324.139310839902\n",
      "Neighborhood_NridgHt 19191.708514339265\n",
      "Condition2_PosN -17535.067429152827\n",
      "KitchenQual_Ex 16930.16768427799\n",
      "BsmtQual_Ex 15503.899708127898\n",
      "Neighborhood_Edwards -14882.341425649654\n",
      "PoolQC_Ex 14086.375637029649\n",
      "\n",
      "Lasso top features:\n",
      "RoofMatl_ClyTile -293450.296624954\n",
      "Condition2_PosN -78503.50367048502\n",
      "Neighborhood_NoRidge 39832.423582177806\n",
      "RoofMatl_WdShngl 39140.19135523638\n",
      "Neighborhood_StoneBr 36868.10564751339\n",
      "KitchenQual_Ex 26010.395834605257\n",
      "Neighborhood_NridgHt 24282.47526134918\n",
      "BsmtQual_Ex 23067.51778464374\n",
      "GrLivArea 21717.879724135746\n",
      "Neighborhood_Crawfor 17174.62298260797\n"
     ]
    }
   ],
   "source": [
    "def get_feature_names_from_preprocessor(pre, numeric_cols, cat_cols):\n",
    "    pre.fit(X)\n",
    "    num_feats = numeric_cols\n",
    "    cat_feats = []\n",
    "    if 'cat' in pre.named_transformers_:\n",
    "        cat_pipe = pre.named_transformers_['cat']\n",
    "        if hasattr(cat_pipe, 'named_steps') and 'onehot' in cat_pipe.named_steps:\n",
    "            ohe = cat_pipe.named_steps['onehot']\n",
    "            cat_in = pre.transformers[1][2]\n",
    "            cat_feats = list(ohe.get_feature_names_out(cat_in))\n",
    "    return num_feats + cat_feats\n",
    "\n",
    "\n",
    "def top_features_for_model(pipe, numeric_cols, cat_cols, top_n=10):\n",
    "    # pipe must be fitted\n",
    "    model = pipe.named_steps[list(pipe.named_steps.keys())[-1]]\n",
    "    feat_names = get_feature_names_from_preprocessor(preprocessor, numeric_cols, cat_cols)\n",
    "    coefs = model.coef_\n",
    "    idx = np.argsort(np.abs(coefs))[::-1][:top_n]\n",
    "    return [(feat_names[i], float(coefs[i])) for i in idx if i < len(feat_names)]\n",
    "\n",
    "from sklearn.linear_model import Ridge\n",
    "ridge_final = make_pipeline(preprocessor, Ridge(alpha=best_alpha_ridge))\n",
    "ridge_final.fit(X, y)\n",
    "lasso_final = lasso_pipe\n",
    "lasso_final.fit(X, y)\n",
    "ridge_top = top_features_for_model(ridge_final, numeric_cols, cat_cols, top_n=10)\n",
    "lasso_top = top_features_for_model(lasso_final, numeric_cols, cat_cols, top_n=10)\n",
    "print('Ridge top features:')\n",
    "for f,v in ridge_top:\n",
    "    print(f, v)\n",
    "print('\\nLasso top features:')\n",
    "for f,v in lasso_top:\n",
    "    print(f, v)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d337041",
   "metadata": {},
   "source": [
    "## 6) Doubling alpha experiment\n",
    "\n",
    "Retrain models with doubled alpha and report training RMSE to show regularisation effect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0a6f7938",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ridge doubled alpha RMSE (train): 26456.68324843526\n",
      "Lasso doubled alpha RMSE (train): 27852.91081211108\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "# Retrain Ridge and Lasso with doubled alpha and compute training RMSE for comparison\n",
    "ridge_double = make_pipeline(preprocessor, Ridge(alpha=best_alpha_ridge*2))\n",
    "ridge_double.fit(X, y)\n",
    "from sklearn.linear_model import Lasso\n",
    "lasso_double = make_pipeline(preprocessor, Lasso(alpha=best_alpha_lasso*2, max_iter=10000))\n",
    "lasso_double.fit(X, y)\n",
    "\n",
    "def rmse_on_train(pipe, X_local=X, y_local=y):\n",
    "    preds = pipe.predict(X_local)\n",
    "    return float(np.sqrt(mean_squared_error(y_local, preds)))\n",
    "\n",
    "print('Ridge doubled alpha RMSE (train):', rmse_on_train(ridge_double))\n",
    "print('Lasso doubled alpha RMSE (train):', rmse_on_train(lasso_double))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63b444fd",
   "metadata": {},
   "source": [
    "## 7) Retrain without top-5 Lasso predictors\n",
    "\n",
    "Drop the top-5 features identified by Lasso and retrain a fallback Lasso model on the reduced dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4ff33e27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-5 Lasso features to remove: ['RoofMatl_ClyTile', 'Condition2_PosN', 'Neighborhood_NoRidge', 'RoofMatl_WdShngl', 'Neighborhood_StoneBr']\n",
      "Top features after removing top-5 Lasso predictors:\n",
      "BsmtQual_Ex 28396.330077116276\n",
      "KitchenQual_Ex 27314.885290084367\n",
      "GrLivArea 23715.353727267026\n",
      "OverallQual 16413.451262640938\n",
      "BsmtExposure_Gd 12533.681758884284\n",
      "Condition1_Norm 10948.947297142802\n",
      "SaleType_New 9910.634360778107\n",
      "Exterior1st_BrkFace 9835.731137166433\n",
      "LandContour_Bnk -8457.050047239156\n",
      "ExterQual_TA -7710.179009207745\n"
     ]
    }
   ],
   "source": [
    "top5 = [f for f,_ in lasso_top[:5]]\n",
    "print('Top-5 Lasso features to remove:', top5)\n",
    "X_reduced = X.copy()\n",
    "for feat in top5:\n",
    "    if feat in X_reduced.columns:\n",
    "        X_reduced = X_reduced.drop(columns=[feat])\n",
    "    else:\n",
    "        if '_' in feat:\n",
    "            base = feat.split('_')[0]\n",
    "            if base in X_reduced.columns:\n",
    "                X_reduced = X_reduced.drop(columns=[base])\n",
    "\n",
    "numeric_cols_r = X_reduced.select_dtypes(include=['int64','float64']).columns.tolist()\n",
    "cat_cols_r = X_reduced.select_dtypes(include=['object']).columns.tolist()\n",
    "\n",
    "numeric_transformer_r = Pipeline([('imputer', SimpleImputer(strategy='median')),('scaler', StandardScaler())])\n",
    "categorical_transformer_r = Pipeline([('imputer', SimpleImputer(strategy='most_frequent')),('onehot', OneHotEncoder(handle_unknown='ignore', sparse_output=False))])\n",
    "preprocessor_r = ColumnTransformer([('num', numeric_transformer_r, numeric_cols_r),('cat', categorical_transformer_r, cat_cols_r)])\n",
    "\n",
    "from sklearn.linear_model import LassoCV\n",
    "lasso_r = make_pipeline(preprocessor_r, LassoCV(alphas=alphas, cv=kf, random_state=42, max_iter=10000))\n",
    "lasso_r.fit(X_reduced, y)\n",
    "\n",
    "# extract new top features\n",
    "preprocessor_r.fit(X_reduced)\n",
    "if 'cat' in preprocessor_r.named_transformers_:\n",
    "    cat_pipe = preprocessor_r.named_transformers_['cat']\n",
    "    ohe = cat_pipe.named_steps['onehot']\n",
    "    cat_in = preprocessor_r.transformers[1][2]\n",
    "    cat_feats_r = list(ohe.get_feature_names_out(cat_in))\n",
    "else:\n",
    "    cat_feats_r = []\n",
    "feat_names_r = numeric_cols_r + cat_feats_r\n",
    "coefs_r = lasso_r.named_steps['lassocv'].coef_\n",
    "idx_r = np.argsort(np.abs(coefs_r))[::-1][:10]\n",
    "lasso_r_top = [(feat_names_r[i], float(coefs_r[i])) for i in idx_r if i < len(feat_names_r)]\n",
    "print('Top features after removing top-5 Lasso predictors:')\n",
    "for f,v in lasso_r_top:\n",
    "    print(f,v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a17b8bc2",
   "metadata": {
    "vscode": {
     "languageId": "code"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model_summary.json\n"
     ]
    }
   ],
   "source": [
    "# Save summary\n",
    "summary = {\n",
    "    'best_alpha_ridge': best_alpha_ridge,\n",
    "    'best_alpha_lasso': float(best_alpha_lasso),\n",
    "    'ridge_rmse_cv': ridge_rmse_cv,\n",
    "    'lasso_rmse_cv': lasso_rmse_cv,\n",
    "    'ridge_top': ridge_top,\n",
    "    'lasso_top': lasso_top,\n",
    "    'top5_lasso_removed': top5,\n",
    "    'lasso_retrained_top': lasso_r_top,\n",
    "}\n",
    "Path('model_summary.json').write_text(json.dumps(summary, indent=2))\n",
    "print('Saved model_summary.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7065bd2f-a3d6-4acd-acbb-1c868877ccba",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (upgrad-ml2)",
   "language": "python",
   "name": "upgrad-ml2-kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
