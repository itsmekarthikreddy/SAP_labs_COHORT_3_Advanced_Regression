{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "256702e3",
      "metadata": {},
      "source": [
        "# House Price Prediction â€” Regularised Regression\n",
        "\n",
        "This notebook implements the full analysis required by the assignment. It is organized into sections: imports, data loading, preprocessing, hyperparameter selection (Ridge & Lasso), feature importance, `alpha` doubling experiment, and retraining when top features are unavailable.\n",
        "\n",
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1dc8c2c1",
      "metadata": {},
      "source": [
        "## 1) Imports and configuration\n",
        "\n",
        "Standard imports and plotting configuration."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "6019e699",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Imports OK\n"
          ]
        }
      ],
      "source": [
        "# Cell: imports\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from pathlib import Path\n",
        "sns.set(style='whitegrid')\n",
        "print('Imports OK')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "2add8fb0",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "json and pprint imported\n"
          ]
        }
      ],
      "source": [
        "# Utility imports used later in the notebook\n",
        "import json\n",
        "from pprint import pprint\n",
        "print('json and pprint imported')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d40562d8",
      "metadata": {},
      "source": [
        "## 2) Load data and quick checks\n",
        "\n",
        "Load `train.csv` (must be in the workspace root) and show basic diagnostics."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "70356bee",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape: (1460, 81)\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "PoolQC         0.995205\n",
              "MiscFeature    0.963014\n",
              "Alley          0.937671\n",
              "Fence          0.807534\n",
              "MasVnrType     0.597260\n",
              "FireplaceQu    0.472603\n",
              "LotFrontage    0.177397\n",
              "GarageYrBlt    0.055479\n",
              "GarageCond     0.055479\n",
              "GarageType     0.055479\n",
              "dtype: float64"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "p = Path('train.csv')\n",
        "assert p.exists(), 'train.csv not found in workspace root'\n",
        "df = pd.read_csv(p)\n",
        "print('Shape:', df.shape)\n",
        "df.head(3)\n",
        "\n",
        "# Basic missingness\n",
        "miss = df.isnull().mean().sort_values(ascending=False)\n",
        "miss[miss>0].head(10)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1edaba7e",
      "metadata": {},
      "source": [
        "## 2.1) Exploratory Data Analysis (EDA)\n",
        "\n",
        "Quick EDA: target distribution, missingness, duplicates, top numeric correlations, and a simple derived feature (`TotalSF`) if available. Figures are saved to disk for the report."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "32380451",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Top missing columns (fraction missing):\n",
            "PoolQC          0.995205\n",
            "MiscFeature     0.963014\n",
            "Alley           0.937671\n",
            "Fence           0.807534\n",
            "MasVnrType      0.597260\n",
            "FireplaceQu     0.472603\n",
            "LotFrontage     0.177397\n",
            "GarageYrBlt     0.055479\n",
            "GarageCond      0.055479\n",
            "GarageType      0.055479\n",
            "GarageFinish    0.055479\n",
            "GarageQual      0.055479\n",
            "BsmtFinType2    0.026027\n",
            "BsmtExposure    0.026027\n",
            "BsmtQual        0.025342\n",
            "BsmtCond        0.025342\n",
            "BsmtFinType1    0.025342\n",
            "MasVnrArea      0.005479\n",
            "Electrical      0.000685\n",
            "dtype: float64\n",
            "Duplicate rows: 0\n",
            "Top numeric correlations with SalePrice:\n",
            "OverallQual     0.790982\n",
            "GrLivArea       0.708624\n",
            "GarageCars      0.640409\n",
            "GarageArea      0.623431\n",
            "TotalBsmtSF     0.613581\n",
            "1stFlrSF        0.605852\n",
            "FullBath        0.560664\n",
            "TotRmsAbvGrd    0.533723\n",
            "YearBuilt       0.522897\n",
            "YearRemodAdd    0.507101\n",
            "dtype: float64\n",
            "Derived feature `TotalSF` created (sum of 1stFlrSF, 2ndFlrSF, TotalBsmtSF)\n"
          ]
        }
      ],
      "source": [
        "# EDA: target distribution, missingness, correlations, duplicates, derived feature\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "plt.rcParams.update({'figure.max_open_warning': 0})\n",
        "# Target distribution\n",
        "plt.figure(figsize=(8,4))\n",
        "sns.histplot(df['SalePrice'], kde=True, color='C0')\n",
        "plt.title('SalePrice distribution')\n",
        "plt.tight_layout()\n",
        "plt.savefig('fig_target_hist.png', bbox_inches='tight')\n",
        "plt.close()\n",
        "plt.figure(figsize=(8,4))\n",
        "sns.histplot(np.log1p(df['SalePrice']), kde=True, color='C1')\n",
        "plt.title('log1p(SalePrice) distribution')\n",
        "plt.tight_layout()\n",
        "plt.savefig('fig_target_log_hist.png', bbox_inches='tight')\n",
        "plt.close()\n",
        "# Missingness summary and small heatmap (top missing columns)\n",
        "miss = df.isnull().mean().sort_values(ascending=False)\n",
        "top_miss = miss[miss>0].head(20)\n",
        "print('Top missing columns (fraction missing):')\n",
        "print(top_miss)\n",
        "if len(top_miss):\n",
        "    plt.figure(figsize=(10,6))\n",
        "    sns.heatmap(df[top_miss.index].isnull(), cbar=False)\n",
        "    plt.title('Missingness heatmap (top columns)')\n",
        "    plt.tight_layout()\n",
        "    plt.savefig('fig_missing_heatmap.png', bbox_inches='tight')\n",
        "    plt.close()\n",
        "# Duplicates check\n",
        "dups = df.duplicated().sum()\n",
        "print('Duplicate rows:', dups)\n",
        "# Numeric correlations with target\n",
        "num = df.select_dtypes(include=['int64','float64']).drop(columns=['SalePrice'])\n",
        "corrs = num.corrwith(df['SalePrice']).abs().sort_values(ascending=False)\n",
        "print('Top numeric correlations with SalePrice:')\n",
        "print(corrs.head(10))\n",
        "plt.figure(figsize=(8,6))\n",
        "sns.barplot(x=corrs.head(10).values, y=corrs.head(10).index, palette='viridis')\n",
        "plt.title('Top numeric features correlated with SalePrice')\n",
        "plt.tight_layout()\n",
        "plt.savefig('fig_top_corrs.png', bbox_inches='tight')\n",
        "plt.close()\n",
        "# Correlation heatmap for top numeric features (if enough exist)\n",
        "top_nums = corrs.head(15).index.tolist()\n",
        "if len(top_nums) > 1:\n",
        "    plt.figure(figsize=(10,8))\n",
        "    sns.heatmap(df[top_nums + ['SalePrice']].corr(), annot=False, cmap='coolwarm')\n",
        "    plt.title('Correlation matrix (top numeric features)')\n",
        "    plt.tight_layout()\n",
        "    plt.savefig('fig_corr_matrix.png', bbox_inches='tight')\n",
        "    plt.close()\n",
        "# Simple derived feature: TotalSF if 1st/2nd/TotalBsmt present\n",
        "derived_cols = ['1stFlrSF','2ndFlrSF','TotalBsmtSF']\n",
        "if all(c in df.columns for c in derived_cols):\n",
        "    df['TotalSF'] = df['1stFlrSF'].fillna(0) + df['2ndFlrSF'].fillna(0) + df['TotalBsmtSF'].fillna(0)\n",
        "    print('Derived feature `TotalSF` created (sum of 1stFlrSF, 2ndFlrSF, TotalBsmtSF)')\n",
        "    plt.figure(figsize=(8,4))\n",
        "    sns.histplot(df['TotalSF'], kde=True, color='C2')\n",
        "    plt.title('TotalSF distribution')\n",
        "    plt.tight_layout()\n",
        "    plt.savefig('fig_totalSF.png', bbox_inches='tight')\n",
        "    plt.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "404198a8",
      "metadata": {},
      "source": [
        "## 3) Preprocessing pipeline\n",
        "\n",
        "Median imputation for numerics, most-frequent for categoricals, StandardScaler for numerics, OneHotEncoder for categoricals."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a118d36e",
      "metadata": {},
      "source": [
        "## 3.1) Train/Test Split and Hold-out Evaluation\n",
        "\n",
        "We split the data into train and test sets (80/20). All model selection and CV are performed on the train set. Final RMSE is reported on the hold-out test set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "8f5c3998",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Numeric cols: 38 Categorical cols: 43\n",
            "Preprocessor ready\n"
          ]
        }
      ],
      "source": [
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
        "\n",
        "# Separate target\n",
        "y = df['SalePrice']\n",
        "X = df.drop(columns=['SalePrice'])\n",
        "numeric_cols = X.select_dtypes(include=['int64','float64']).columns.tolist()\n",
        "cat_cols = X.select_dtypes(include=['object']).columns.tolist()\n",
        "print('Numeric cols:', len(numeric_cols), 'Categorical cols:', len(cat_cols))\n",
        "\n",
        "numeric_transformer = Pipeline([('imputer', SimpleImputer(strategy='median')),('scaler', StandardScaler())])\n",
        "categorical_transformer = Pipeline([('imputer', SimpleImputer(strategy='most_frequent')),('onehot', OneHotEncoder(handle_unknown='ignore', sparse_output=False))])\n",
        "preprocessor = ColumnTransformer([('num', numeric_transformer, numeric_cols),('cat', categorical_transformer, cat_cols)])\n",
        "print('Preprocessor ready')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ef394289",
      "metadata": {},
      "source": [
        "## 4) Hyperparameter selection (alpha grid) and cross-validation\n",
        "\n",
        "We use a log-spaced alpha grid and 5-fold CV. For Lasso we use `LassoCV` to get the full path; for Ridge we compute CV RMSE per alpha and pick the best."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "6af1e690",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best Ridge alpha: 14.563484775012444\n",
            "Best Lasso alpha: 138.9495494373136\n",
            "Ridge CV RMSE: 33042.22437265117\n",
            "Lasso CV RMSE: 31567.206937142975\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import KFold, cross_val_score\n",
        "from sklearn.linear_model import LassoCV, Ridge\n",
        "alphas = np.logspace(-3, 3, 50)\n",
        "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "# Ridge CV (manual grid)\n",
        "ridge_rmse = []\n",
        "from sklearn.pipeline import make_pipeline\n",
        "for a in alphas:\n",
        "    pipe = make_pipeline(preprocessor, Ridge(alpha=a))\n",
        "    scores = cross_val_score(pipe, X, y, cv=kf, scoring='neg_mean_squared_error')\n",
        "    ridge_rmse.append(np.sqrt(-scores).mean())\n",
        "# LassoCV (uses internal CV)\n",
        "lasso_pipe = make_pipeline(preprocessor, LassoCV(alphas=alphas, cv=kf, random_state=42, max_iter=10000))\n",
        "lasso_pipe.fit(X, y)\n",
        "best_alpha_lasso = lasso_pipe.named_steps['lassocv'].alpha_\n",
        "# Pick best ridge alpha from grid\n",
        "best_idx = int(np.argmin(ridge_rmse))\n",
        "best_alpha_ridge = float(alphas[best_idx])\n",
        "# Compute CV RMSE summary\n",
        "ridge_rmse_cv = float(ridge_rmse[best_idx])\n",
        "# For Lasso, compute CV RMSE from mse_path_ if available\n",
        "lasso_model = lasso_pipe.named_steps['lassocv']\n",
        "mse_path = getattr(lasso_model, 'mse_path_', None)\n",
        "if mse_path is not None:\n",
        "    lasso_rmse_vals = np.sqrt(mse_path).mean(axis=1)\n",
        "    # find index for selected alpha in model.alphas_\n",
        "    if hasattr(lasso_model, 'alphas_'):\n",
        "        idx = int(np.argmin(np.abs(lasso_model.alphas_ - lasso_model.alpha_)))\n",
        "        lasso_rmse_cv = float(lasso_rmse_vals[idx])\n",
        "    else:\n",
        "        lasso_rmse_cv = float(np.sqrt(np.mean((y - lasso_pipe.predict(X))**2)))\n",
        "else:\n",
        "    lasso_rmse_cv = float(np.sqrt(np.mean((y - lasso_pipe.predict(X))**2)))\n",
        "print('Best Ridge alpha:', best_alpha_ridge)\n",
        "print('Best Lasso alpha:', best_alpha_lasso)\n",
        "print('Ridge CV RMSE:', ridge_rmse_cv)\n",
        "print('Lasso CV RMSE:', lasso_rmse_cv)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2c75d57b",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Ensure a hold-out train/test split exists before training on the train set\n",
        "from sklearn.model_selection import train_test_split\n",
        "if 'X' not in globals() or 'y' not in globals():\n",
        "    y = df['SalePrice']\n",
        "    X = df.drop(columns=['SalePrice'])\n",
        "# create a deterministic 80/20 split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "print('Train / Test shapes:', X_train.shape, X_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "99286b2b",
      "metadata": {},
      "outputs": [
        {
          "ename": "ValueError",
          "evalue": "\nAll the 5 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n5 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/Users/i530634/upgrad-ML2/.venv/lib/python3.14/site-packages/pandas/core/indexes/base.py\", line 3812, in get_loc\n    return self._engine.get_loc(casted_key)\n           ~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^\n  File \"pandas/_libs/index.pyx\", line 167, in pandas._libs.index.IndexEngine.get_loc\n  File \"pandas/_libs/index.pyx\", line 196, in pandas._libs.index.IndexEngine.get_loc\n  File \"pandas/_libs/hashtable_class_helper.pxi\", line 7088, in pandas._libs.hashtable.PyObjectHashTable.get_item\n  File \"pandas/_libs/hashtable_class_helper.pxi\", line 7096, in pandas._libs.hashtable.PyObjectHashTable.get_item\nKeyError: 'TotalSF'\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/Users/i530634/upgrad-ML2/.venv/lib/python3.14/site-packages/sklearn/utils/_indexing.py\", line 469, in _get_column_indices\n    col_idx = all_columns.get_loc(col)\n  File \"/Users/i530634/upgrad-ML2/.venv/lib/python3.14/site-packages/pandas/core/indexes/base.py\", line 3819, in get_loc\n    raise KeyError(key) from err\nKeyError: 'TotalSF'\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/Users/i530634/upgrad-ML2/.venv/lib/python3.14/site-packages/sklearn/model_selection/_validation.py\", line 833, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n    ~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/i530634/upgrad-ML2/.venv/lib/python3.14/site-packages/sklearn/base.py\", line 1336, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/i530634/upgrad-ML2/.venv/lib/python3.14/site-packages/sklearn/pipeline.py\", line 613, in fit\n    Xt = self._fit(X, y, routed_params, raw_params=params)\n  File \"/Users/i530634/upgrad-ML2/.venv/lib/python3.14/site-packages/sklearn/pipeline.py\", line 547, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n                            ~~~~~~~~~~~~~~~~~~~~~~~~^\n        cloned_transformer,\n        ^^^^^^^^^^^^^^^^^^^\n    ...<5 lines>...\n        params=step_params,\n        ^^^^^^^^^^^^^^^^^^^\n    )\n    ^\n  File \"/Users/i530634/upgrad-ML2/.venv/lib/python3.14/site-packages/joblib/memory.py\", line 326, in __call__\n    return self.func(*args, **kwargs)\n           ~~~~~~~~~^^^^^^^^^^^^^^^^^\n  File \"/Users/i530634/upgrad-ML2/.venv/lib/python3.14/site-packages/sklearn/pipeline.py\", line 1484, in _fit_transform_one\n    res = transformer.fit_transform(X, y, **params.get(\"fit_transform\", {}))\n  File \"/Users/i530634/upgrad-ML2/.venv/lib/python3.14/site-packages/sklearn/utils/_set_output.py\", line 316, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n  File \"/Users/i530634/upgrad-ML2/.venv/lib/python3.14/site-packages/sklearn/base.py\", line 1336, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/i530634/upgrad-ML2/.venv/lib/python3.14/site-packages/sklearn/compose/_column_transformer.py\", line 991, in fit_transform\n    self._validate_column_callables(X)\n    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^\n  File \"/Users/i530634/upgrad-ML2/.venv/lib/python3.14/site-packages/sklearn/compose/_column_transformer.py\", line 545, in _validate_column_callables\n    transformer_to_input_indices[name] = _get_column_indices(X, columns)\n                                         ~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^\n  File \"/Users/i530634/upgrad-ML2/.venv/lib/python3.14/site-packages/sklearn/utils/_indexing.py\", line 477, in _get_column_indices\n    raise ValueError(\"A given column is not a column of the dataframe\") from e\nValueError: A given column is not a column of the dataframe\n",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[23]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m a \u001b[38;5;129;01min\u001b[39;00m alphas:\n\u001b[32m      4\u001b[39m     pipe = make_pipeline(preprocessor, Ridge(alpha=a))\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m     scores = \u001b[43mcross_val_score\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpipe\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcv\u001b[49m\u001b[43m=\u001b[49m\u001b[43mkf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscoring\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mneg_mean_squared_error\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      6\u001b[39m     ridge_rmse_tr.append(np.sqrt(-scores).mean())\n\u001b[32m      7\u001b[39m best_idx_tr = \u001b[38;5;28mint\u001b[39m(np.argmin(ridge_rmse_tr))\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/upgrad-ML2/.venv/lib/python3.14/site-packages/sklearn/utils/_param_validation.py:218\u001b[39m, in \u001b[36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    212\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    213\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m    214\u001b[39m         skip_parameter_validation=(\n\u001b[32m    215\u001b[39m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m    216\u001b[39m         )\n\u001b[32m    217\u001b[39m     ):\n\u001b[32m--> \u001b[39m\u001b[32m218\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    219\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    220\u001b[39m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[32m    221\u001b[39m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[32m    222\u001b[39m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[32m    223\u001b[39m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[32m    224\u001b[39m     msg = re.sub(\n\u001b[32m    225\u001b[39m         \u001b[33mr\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mparameter of \u001b[39m\u001b[33m\\\u001b[39m\u001b[33mw+ must be\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    226\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc.\u001b[34m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m must be\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    227\u001b[39m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[32m    228\u001b[39m     )\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/upgrad-ML2/.venv/lib/python3.14/site-packages/sklearn/model_selection/_validation.py:651\u001b[39m, in \u001b[36mcross_val_score\u001b[39m\u001b[34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, params, pre_dispatch, error_score)\u001b[39m\n\u001b[32m    648\u001b[39m \u001b[38;5;66;03m# To ensure multimetric format is not supported\u001b[39;00m\n\u001b[32m    649\u001b[39m scorer = check_scoring(estimator, scoring=scoring)\n\u001b[32m--> \u001b[39m\u001b[32m651\u001b[39m cv_results = \u001b[43mcross_validate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    652\u001b[39m \u001b[43m    \u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m=\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    653\u001b[39m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m=\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    654\u001b[39m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[43m=\u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    655\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgroups\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroups\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    656\u001b[39m \u001b[43m    \u001b[49m\u001b[43mscoring\u001b[49m\u001b[43m=\u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mscore\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mscorer\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    657\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcv\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    658\u001b[39m \u001b[43m    \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    659\u001b[39m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    660\u001b[39m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    661\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpre_dispatch\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpre_dispatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    662\u001b[39m \u001b[43m    \u001b[49m\u001b[43merror_score\u001b[49m\u001b[43m=\u001b[49m\u001b[43merror_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    663\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    664\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m cv_results[\u001b[33m\"\u001b[39m\u001b[33mtest_score\u001b[39m\u001b[33m\"\u001b[39m]\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/upgrad-ML2/.venv/lib/python3.14/site-packages/sklearn/utils/_param_validation.py:218\u001b[39m, in \u001b[36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    212\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    213\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m    214\u001b[39m         skip_parameter_validation=(\n\u001b[32m    215\u001b[39m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m    216\u001b[39m         )\n\u001b[32m    217\u001b[39m     ):\n\u001b[32m--> \u001b[39m\u001b[32m218\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    219\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    220\u001b[39m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[32m    221\u001b[39m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[32m    222\u001b[39m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[32m    223\u001b[39m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[32m    224\u001b[39m     msg = re.sub(\n\u001b[32m    225\u001b[39m         \u001b[33mr\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mparameter of \u001b[39m\u001b[33m\\\u001b[39m\u001b[33mw+ must be\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    226\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc.\u001b[34m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m must be\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    227\u001b[39m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[32m    228\u001b[39m     )\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/upgrad-ML2/.venv/lib/python3.14/site-packages/sklearn/model_selection/_validation.py:393\u001b[39m, in \u001b[36mcross_validate\u001b[39m\u001b[34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, params, pre_dispatch, return_train_score, return_estimator, return_indices, error_score)\u001b[39m\n\u001b[32m    372\u001b[39m parallel = Parallel(n_jobs=n_jobs, verbose=verbose, pre_dispatch=pre_dispatch)\n\u001b[32m    373\u001b[39m results = parallel(\n\u001b[32m    374\u001b[39m     delayed(_fit_and_score)(\n\u001b[32m    375\u001b[39m         clone(estimator),\n\u001b[32m   (...)\u001b[39m\u001b[32m    390\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m train, test \u001b[38;5;129;01min\u001b[39;00m indices\n\u001b[32m    391\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m393\u001b[39m \u001b[43m_warn_or_raise_about_fit_failures\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresults\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merror_score\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    395\u001b[39m \u001b[38;5;66;03m# For callable scoring, the return type is only know after calling. If the\u001b[39;00m\n\u001b[32m    396\u001b[39m \u001b[38;5;66;03m# return type is a dictionary, the error scores can now be inserted with\u001b[39;00m\n\u001b[32m    397\u001b[39m \u001b[38;5;66;03m# the correct key.\u001b[39;00m\n\u001b[32m    398\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(scoring):\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/upgrad-ML2/.venv/lib/python3.14/site-packages/sklearn/model_selection/_validation.py:479\u001b[39m, in \u001b[36m_warn_or_raise_about_fit_failures\u001b[39m\u001b[34m(results, error_score)\u001b[39m\n\u001b[32m    472\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m num_failed_fits == num_fits:\n\u001b[32m    473\u001b[39m     all_fits_failed_message = (\n\u001b[32m    474\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mAll the \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m fits failed.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    475\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mIt is very likely that your model is misconfigured.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    476\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mYou can try to debug the error by setting error_score=\u001b[39m\u001b[33m'\u001b[39m\u001b[33mraise\u001b[39m\u001b[33m'\u001b[39m\u001b[33m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    477\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mBelow are more details about the failures:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mfit_errors_summary\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    478\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m479\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(all_fits_failed_message)\n\u001b[32m    481\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    482\u001b[39m     some_fits_failed_message = (\n\u001b[32m    483\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mnum_failed_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m fits failed out of a total of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    484\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mThe score on these train-test partitions for these parameters\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   (...)\u001b[39m\u001b[32m    488\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mBelow are more details about the failures:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mfit_errors_summary\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    489\u001b[39m     )\n",
            "\u001b[31mValueError\u001b[39m: \nAll the 5 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n5 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/Users/i530634/upgrad-ML2/.venv/lib/python3.14/site-packages/pandas/core/indexes/base.py\", line 3812, in get_loc\n    return self._engine.get_loc(casted_key)\n           ~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^\n  File \"pandas/_libs/index.pyx\", line 167, in pandas._libs.index.IndexEngine.get_loc\n  File \"pandas/_libs/index.pyx\", line 196, in pandas._libs.index.IndexEngine.get_loc\n  File \"pandas/_libs/hashtable_class_helper.pxi\", line 7088, in pandas._libs.hashtable.PyObjectHashTable.get_item\n  File \"pandas/_libs/hashtable_class_helper.pxi\", line 7096, in pandas._libs.hashtable.PyObjectHashTable.get_item\nKeyError: 'TotalSF'\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/Users/i530634/upgrad-ML2/.venv/lib/python3.14/site-packages/sklearn/utils/_indexing.py\", line 469, in _get_column_indices\n    col_idx = all_columns.get_loc(col)\n  File \"/Users/i530634/upgrad-ML2/.venv/lib/python3.14/site-packages/pandas/core/indexes/base.py\", line 3819, in get_loc\n    raise KeyError(key) from err\nKeyError: 'TotalSF'\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/Users/i530634/upgrad-ML2/.venv/lib/python3.14/site-packages/sklearn/model_selection/_validation.py\", line 833, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n    ~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/i530634/upgrad-ML2/.venv/lib/python3.14/site-packages/sklearn/base.py\", line 1336, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/i530634/upgrad-ML2/.venv/lib/python3.14/site-packages/sklearn/pipeline.py\", line 613, in fit\n    Xt = self._fit(X, y, routed_params, raw_params=params)\n  File \"/Users/i530634/upgrad-ML2/.venv/lib/python3.14/site-packages/sklearn/pipeline.py\", line 547, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n                            ~~~~~~~~~~~~~~~~~~~~~~~~^\n        cloned_transformer,\n        ^^^^^^^^^^^^^^^^^^^\n    ...<5 lines>...\n        params=step_params,\n        ^^^^^^^^^^^^^^^^^^^\n    )\n    ^\n  File \"/Users/i530634/upgrad-ML2/.venv/lib/python3.14/site-packages/joblib/memory.py\", line 326, in __call__\n    return self.func(*args, **kwargs)\n           ~~~~~~~~~^^^^^^^^^^^^^^^^^\n  File \"/Users/i530634/upgrad-ML2/.venv/lib/python3.14/site-packages/sklearn/pipeline.py\", line 1484, in _fit_transform_one\n    res = transformer.fit_transform(X, y, **params.get(\"fit_transform\", {}))\n  File \"/Users/i530634/upgrad-ML2/.venv/lib/python3.14/site-packages/sklearn/utils/_set_output.py\", line 316, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n  File \"/Users/i530634/upgrad-ML2/.venv/lib/python3.14/site-packages/sklearn/base.py\", line 1336, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/i530634/upgrad-ML2/.venv/lib/python3.14/site-packages/sklearn/compose/_column_transformer.py\", line 991, in fit_transform\n    self._validate_column_callables(X)\n    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^\n  File \"/Users/i530634/upgrad-ML2/.venv/lib/python3.14/site-packages/sklearn/compose/_column_transformer.py\", line 545, in _validate_column_callables\n    transformer_to_input_indices[name] = _get_column_indices(X, columns)\n                                         ~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^\n  File \"/Users/i530634/upgrad-ML2/.venv/lib/python3.14/site-packages/sklearn/utils/_indexing.py\", line 477, in _get_column_indices\n    raise ValueError(\"A given column is not a column of the dataframe\") from e\nValueError: A given column is not a column of the dataframe\n"
          ]
        }
      ],
      "source": [
        "# Repeat model selection on train set only, then evaluate on test set\n",
        "ridge_rmse_tr = []\n",
        "for a in alphas:\n",
        "    pipe = make_pipeline(preprocessor, Ridge(alpha=a))\n",
        "    scores = cross_val_score(pipe, X_train, y_train, cv=kf, scoring='neg_mean_squared_error')\n",
        "    ridge_rmse_tr.append(np.sqrt(-scores).mean())\n",
        "best_idx_tr = int(np.argmin(ridge_rmse_tr))\n",
        "best_alpha_ridge_tr = float(alphas[best_idx_tr])\n",
        "ridge_final_tr = make_pipeline(preprocessor, Ridge(alpha=best_alpha_ridge_tr))\n",
        "ridge_final_tr.fit(X_train, y_train)\n",
        "ridge_test_preds = ridge_final_tr.predict(X_test)\n",
        "ridge_test_rmse = float(np.sqrt(np.mean((y_test - ridge_test_preds)**2)))\n",
        "print('Ridge test RMSE:', ridge_test_rmse)\n",
        "# LassoCV on train set\n",
        "lasso_pipe_tr = make_pipeline(preprocessor, LassoCV(alphas=alphas, cv=kf, random_state=42, max_iter=10000))\n",
        "lasso_pipe_tr.fit(X_train, y_train)\n",
        "best_alpha_lasso_tr = lasso_pipe_tr.named_steps['lassocv'].alpha_\n",
        "lasso_test_preds = lasso_pipe_tr.predict(X_test)\n",
        "lasso_test_rmse = float(np.sqrt(np.mean((y_test - lasso_test_preds)**2)))\n",
        "print('Lasso test RMSE:', lasso_test_rmse)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "db63645e",
      "metadata": {},
      "source": [
        "## 5) Feature importance\n",
        "\n",
        "Map fitted coefficients back to original feature names and display the top predictors for Ridge and Lasso."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "18bec683",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ridge top features:\n",
            "Neighborhood_NoRidge 25802.129287142976\n",
            "Neighborhood_StoneBr 20836.301606036148\n",
            "RoofMatl_ClyTile -17622.527979352602\n",
            "Neighborhood_NridgHt 17551.670719885038\n",
            "RoofMatl_WdShngl 17319.43517638858\n",
            "KitchenQual_Ex 16403.49816594565\n",
            "BsmtQual_Ex 15248.095675224386\n",
            "GrLivArea 14117.392367635286\n",
            "Condition2_PosN -13850.96368043243\n",
            "Neighborhood_Edwards -13777.936803434473\n",
            "\n",
            "Lasso top features:\n",
            "RoofMatl_ClyTile -292218.7201213501\n",
            "Condition2_PosN -78388.55167568507\n",
            "Neighborhood_NoRidge 39855.42456136982\n",
            "RoofMatl_WdShngl 39197.748087485954\n",
            "Neighborhood_StoneBr 36898.09500926733\n",
            "KitchenQual_Ex 26020.668040812965\n",
            "GrLivArea 25411.504959883434\n",
            "Neighborhood_NridgHt 24326.4132764074\n",
            "BsmtQual_Ex 23097.76672141042\n",
            "Neighborhood_Crawfor 17153.51969585601\n"
          ]
        }
      ],
      "source": [
        "def get_feature_names_from_preprocessor(pre, numeric_cols, cat_cols):\n",
        "    pre.fit(X)\n",
        "    num_feats = numeric_cols\n",
        "    cat_feats = []\n",
        "    if 'cat' in pre.named_transformers_:\n",
        "        cat_pipe = pre.named_transformers_['cat']\n",
        "        if hasattr(cat_pipe, 'named_steps') and 'onehot' in cat_pipe.named_steps:\n",
        "            ohe = cat_pipe.named_steps['onehot']\n",
        "            cat_in = pre.transformers[1][2]\n",
        "            cat_feats = list(ohe.get_feature_names_out(cat_in))\n",
        "    return num_feats + cat_feats\n",
        "\n",
        "\n",
        "def top_features_for_model(pipe, numeric_cols, cat_cols, top_n=10):\n",
        "    # pipe must be fitted\n",
        "    model = pipe.named_steps[list(pipe.named_steps.keys())[-1]]\n",
        "    feat_names = get_feature_names_from_preprocessor(preprocessor, numeric_cols, cat_cols)\n",
        "    coefs = model.coef_\n",
        "    idx = np.argsort(np.abs(coefs))[::-1][:top_n]\n",
        "    return [(feat_names[i], float(coefs[i])) for i in idx if i < len(feat_names)]\n",
        "\n",
        "from sklearn.linear_model import Ridge\n",
        "ridge_final = make_pipeline(preprocessor, Ridge(alpha=best_alpha_ridge))\n",
        "ridge_final.fit(X, y)\n",
        "lasso_final = lasso_pipe\n",
        "lasso_final.fit(X, y)\n",
        "ridge_top = top_features_for_model(ridge_final, numeric_cols, cat_cols, top_n=10)\n",
        "lasso_top = top_features_for_model(lasso_final, numeric_cols, cat_cols, top_n=10)\n",
        "print('Ridge top features:')\n",
        "for f,v in ridge_top:\n",
        "    print(f, v)\n",
        "print('\\nLasso top features:')\n",
        "for f,v in lasso_top:\n",
        "    print(f, v)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9d337041",
      "metadata": {},
      "source": [
        "## 6) Doubling alpha experiment\n",
        "\n",
        "Retrain models with doubled alpha and report training RMSE to show regularisation effect."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0a6f7938",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ridge doubled alpha RMSE (train): 26873.93261530499\n",
            "Lasso doubled alpha RMSE (train): 27849.64028401645\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import mean_squared_error\n",
        "# Retrain Ridge and Lasso with doubled alpha and compute training RMSE for comparison\n",
        "ridge_double = make_pipeline(preprocessor, Ridge(alpha=best_alpha_ridge*2))\n",
        "ridge_double.fit(X, y)\n",
        "from sklearn.linear_model import Lasso\n",
        "lasso_double = make_pipeline(preprocessor, Lasso(alpha=best_alpha_lasso*2, max_iter=10000))\n",
        "lasso_double.fit(X, y)\n",
        "\n",
        "def rmse_on_train(pipe, X_local=X, y_local=y):\n",
        "    preds = pipe.predict(X_local)\n",
        "    return float(np.sqrt(mean_squared_error(y_local, preds)))\n",
        "\n",
        "print('Ridge doubled alpha RMSE (train):', rmse_on_train(ridge_double))\n",
        "print('Lasso doubled alpha RMSE (train):', rmse_on_train(lasso_double))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "63b444fd",
      "metadata": {},
      "source": [
        "## 7) Retrain without top-5 Lasso predictors\n",
        "\n",
        "Drop the top-5 features identified by Lasso and retrain a fallback Lasso model on the reduced dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4ff33e27",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Top-5 Lasso features to remove: ['RoofMatl_ClyTile', 'Condition2_PosN', 'Neighborhood_NoRidge', 'RoofMatl_WdShngl', 'Neighborhood_StoneBr']\n",
            "Top features after removing top-5 Lasso predictors:\n",
            "BsmtQual_Ex 27916.197721555913\n",
            "KitchenQual_Ex 26471.143431293993\n",
            "GrLivArea 25923.177199301288\n",
            "OverallQual 17165.203034598297\n",
            "BsmtExposure_Gd 11396.77715938662\n",
            "Condition1_Norm 10137.577854161458\n",
            "SaleType_New 8760.67027359978\n",
            "GarageCars 7678.098584555795\n",
            "ExterQual_TA -7579.105703137004\n",
            "Exterior1st_BrkFace 6524.584931881699\n"
          ]
        }
      ],
      "source": [
        "top5 = [f for f,_ in lasso_top[:5]]\n",
        "print('Top-5 Lasso features to remove:', top5)\n",
        "X_reduced = X.copy()\n",
        "for feat in top5:\n",
        "    if feat in X_reduced.columns:\n",
        "        X_reduced = X_reduced.drop(columns=[feat])\n",
        "    else:\n",
        "        if '_' in feat:\n",
        "            base = feat.split('_')[0]\n",
        "            if base in X_reduced.columns:\n",
        "                X_reduced = X_reduced.drop(columns=[base])\n",
        "\n",
        "numeric_cols_r = X_reduced.select_dtypes(include=['int64','float64']).columns.tolist()\n",
        "cat_cols_r = X_reduced.select_dtypes(include=['object']).columns.tolist()\n",
        "\n",
        "numeric_transformer_r = Pipeline([('imputer', SimpleImputer(strategy='median')),('scaler', StandardScaler())])\n",
        "categorical_transformer_r = Pipeline([('imputer', SimpleImputer(strategy='most_frequent')),('onehot', OneHotEncoder(handle_unknown='ignore', sparse_output=False))])\n",
        "preprocessor_r = ColumnTransformer([('num', numeric_transformer_r, numeric_cols_r),('cat', categorical_transformer_r, cat_cols_r)])\n",
        "\n",
        "from sklearn.linear_model import LassoCV\n",
        "lasso_r = make_pipeline(preprocessor_r, LassoCV(alphas=alphas, cv=kf, random_state=42, max_iter=10000))\n",
        "lasso_r.fit(X_reduced, y)\n",
        "\n",
        "# extract new top features\n",
        "preprocessor_r.fit(X_reduced)\n",
        "if 'cat' in preprocessor_r.named_transformers_:\n",
        "    cat_pipe = preprocessor_r.named_transformers_['cat']\n",
        "    ohe = cat_pipe.named_steps['onehot']\n",
        "    cat_in = preprocessor_r.transformers[1][2]\n",
        "    cat_feats_r = list(ohe.get_feature_names_out(cat_in))\n",
        "else:\n",
        "    cat_feats_r = []\n",
        "feat_names_r = numeric_cols_r + cat_feats_r\n",
        "coefs_r = lasso_r.named_steps['lassocv'].coef_\n",
        "idx_r = np.argsort(np.abs(coefs_r))[::-1][:10]\n",
        "lasso_r_top = [(feat_names_r[i], float(coefs_r[i])) for i in idx_r if i < len(feat_names_r)]\n",
        "print('Top features after removing top-5 Lasso predictors:')\n",
        "for f,v in lasso_r_top:\n",
        "    print(f,v)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a17b8bc2",
      "metadata": {
        "vscode": {
          "languageId": "code"
        }
      },
      "outputs": [],
      "source": [
        "# Save summary\n",
        "summary = {\n",
        "    'best_alpha_ridge': best_alpha_ridge,\n",
        "    'best_alpha_lasso': float(best_alpha_lasso),\n",
        "    'ridge_rmse_cv': ridge_rmse_cv,\n",
        "    'lasso_rmse_cv': lasso_rmse_cv,\n",
        "    'ridge_top': ridge_top,\n",
        "    'lasso_top': lasso_top,\n",
        "    'top5_lasso_removed': top5,\n",
        "    'lasso_retrained_top': lasso_r_top,\n",
        "    'ridge_test_rmse': ridge_test_rmse,\n",
        "    'lasso_test_rmse': lasso_test_rmse,\n",
        "}\n",
        "Path('model_summary.json').write_text(json.dumps(summary, indent=2))\n",
        "print('Saved model_summary.json')"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.14.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
